{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPhTjmwRIfc/HvS44VEqsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/developer-john67/Gaming_app/blob/main/NLP-practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2jmbYr8K53FN"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2ACheST6GoM",
        "outputId": "3dd2ea65-6a41-4388-9eac-bcfecb8a8664"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mock_corpus.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "ksS9zE0N6Oqx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/Restaurant_Reviews.tsv.txt', delimiter= '\\t', quoting = 3)"
      ],
      "metadata": {
        "id": "IBiPl3Yt6foD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C4T73BYN63QZ",
        "outputId": "de40f0d2-50ab-4ae8-948b-f35470707cf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8424ef72-d81f-480c-a6b1-a0c930d1d3f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8424ef72-d81f-480c-a6b1-a0c930d1d3f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8424ef72-d81f-480c-a6b1-a0c930d1d3f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8424ef72-d81f-480c-a6b1-a0c930d1d3f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"They were excellent.\",\n          \"Your servers suck, wait, correction, our server Heimer sucked.\",\n          \"Will be back again!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Liked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHdolQAj6664",
        "outputId": "c88ffd99-078b-4ecd-89b5-ff7cbf95c3f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  1000 non-null   object\n",
            " 1   Liked   1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Jm92McYB8qwi",
        "outputId": "fb320933-3f73-44d3-956f-1afc62c2ff12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Liked\n",
              "count  1000.00000\n",
              "mean      0.50000\n",
              "std       0.50025\n",
              "min       0.00000\n",
              "25%       0.00000\n",
              "50%       0.50000\n",
              "75%       1.00000\n",
              "max       1.00000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ee63a54-1a58-445e-a1ab-424806863ce8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ee63a54-1a58-445e-a1ab-424806863ce8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ee63a54-1a58-445e-a1ab-424806863ce8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ee63a54-1a58-445e-a1ab-424806863ce8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Liked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353.37680339312715,\n        \"min\": 0.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5,\n          1.0,\n          0.5002501876563868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IUQLgR6b86fS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x= 'Liked', data= df)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "PkzcyZEH9CnC",
        "outputId": "4c609844-762d-4347-e788-6521a3aa3af6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "JP5BdrhH9Rbr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "5yBTPnSHB8lU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps= PorterStemmer()"
      ],
      "metadata": {
        "id": "5e7B5t90CVmU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus= []\n",
        "for i in range (0, 1000):\n",
        "  customer_review= re.sub('[^a-zA-Z]',' ', df['Review'][i])\n",
        "  customer_review= customer_review.lower()\n",
        "  customer_review= customer_review.split()\n",
        "  clean_review= (ps.stem(word) for word in customer_review if not word in set(stopwords.words('english')))\n",
        "  clean_review= ' '.join(clean_review)\n",
        "  corpus.append(clean_review)"
      ],
      "metadata": {
        "id": "O8M2PBtECZsU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJjDMD3EE0SI",
        "outputId": "ee8cd3bc-081a-4d33-8ab5-3cb6e1b6db77"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fbb1Ct6ZE3nh",
        "outputId": "9f9092f0-d6d1-4d25-c185-d81be5273f3b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cashier care ever say still end wayyy overpr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TDxQzGWGHAd2",
        "outputId": "9dfd866b-87f0-4653-9bbd-d5a57e80b437"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wow love place'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer= TfidfVectorizer(max_features= 1500, min_df= 3, max_df= 0.6)"
      ],
      "metadata": {
        "id": "-5UCDaqxHF-n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= vectorizer.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "YUj8HldQHZ_H"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybzJxymaILBT",
        "outputId": "32d582ff-ded8-47cd-be50-62b2bdc0440a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfz2r2AYIfoU",
        "outputId": "7ed8c1fe-f53a-441b-eff3-1d50eab70e9d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.51611335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.37891311, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.76814834, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df.iloc[:, 1].values"
      ],
      "metadata": {
        "id": "WEW1kDjCIi3z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbnE4crUIt5s",
        "outputId": "8362e99b-0477-496e-c55d-6d21ac01edc5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)"
      ],
      "metadata": {
        "id": "q4Aq9BTSIx6F"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "cPeUcsd5JZIX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_= X_train.float()\n",
        "Xtest_= X_test.float()"
      ],
      "metadata": {
        "id": "OdkbPeIlKJSB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_= torch.from_numpy(y_train)\n",
        "ytest_= torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "RTdMyslVKzR7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_.shape, ytrain_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdZjr-XmK0db",
        "outputId": "03f9bbc9-318d-4059-f567-540f19bd5e65"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([800, 467]), torch.Size([800]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest_.shape, ytest_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TagWXTtqK4N7",
        "outputId": "b591104e-2ec1-4d80-ec32-d07c53d8e279"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 467]), torch.Size([200]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=467\n",
        "output_size=2\n",
        "hidden_size=500"
      ],
      "metadata": {
        "id": "082OkwXuMBeW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1= torch.nn.Linear(input_size, hidden_size)\n",
        "    self.fc2= torch.nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3= torch.nn.Linear(hidden_size, output_size)\n",
        "  def forward(self, x):\n",
        "    x= torch.relu(self.fc1(x))\n",
        "    x= torch.relu(self.fc2(x))\n",
        "    x= self.fc3(x)\n",
        "    return F.log_softmax(x, dim= 1)"
      ],
      "metadata": {
        "id": "2-JwLLxuMlna"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= Net()"
      ],
      "metadata": {
        "id": "BnfRIl9rOJ4m"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= torch.optim.Adam(model.parameters(), lr= 0.01)\n",
        "loss_fn= nn.NLLLoss()"
      ],
      "metadata": {
        "id": "JJP5n0MOOOrd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs= 100"
      ],
      "metadata": {
        "id": "aX8aFugPPX_9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  ypred= model(Xtrain_)\n",
        "  loss= loss_fn(ypred, ytrain_)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print('Epoch', epoch, 'loss', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRSA-sP4PasK",
        "outputId": "f262289f-51a3-4167-f57f-178ac039839d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss 0.01897571235895157\n",
            "Epoch 1 loss 0.09431459754705429\n",
            "Epoch 2 loss 0.024929584935307503\n",
            "Epoch 3 loss 0.026376262307167053\n",
            "Epoch 4 loss 0.028436221182346344\n",
            "Epoch 5 loss 0.026257043704390526\n",
            "Epoch 6 loss 0.02421862818300724\n",
            "Epoch 7 loss 0.022035248577594757\n",
            "Epoch 8 loss 0.02118634432554245\n",
            "Epoch 9 loss 0.02143925242125988\n",
            "Epoch 10 loss 0.020714811980724335\n",
            "Epoch 11 loss 0.019931241869926453\n",
            "Epoch 12 loss 0.019498487934470177\n",
            "Epoch 13 loss 0.01932697743177414\n",
            "Epoch 14 loss 0.01930723525583744\n",
            "Epoch 15 loss 0.01927884854376316\n",
            "Epoch 16 loss 0.01921938918530941\n",
            "Epoch 17 loss 0.01916966214776039\n",
            "Epoch 18 loss 0.01908152736723423\n",
            "Epoch 19 loss 0.019025739282369614\n",
            "Epoch 20 loss 0.01906048133969307\n",
            "Epoch 21 loss 0.019097236916422844\n",
            "Epoch 22 loss 0.01907210238277912\n",
            "Epoch 23 loss 0.01901119388639927\n",
            "Epoch 24 loss 0.018987415358424187\n",
            "Epoch 25 loss 0.019006218761205673\n",
            "Epoch 26 loss 0.01901669055223465\n",
            "Epoch 27 loss 0.019006459042429924\n",
            "Epoch 28 loss 0.018990488722920418\n",
            "Epoch 29 loss 0.018980156630277634\n",
            "Epoch 30 loss 0.01898106187582016\n",
            "Epoch 31 loss 0.018987704068422318\n",
            "Epoch 32 loss 0.018986592069268227\n",
            "Epoch 33 loss 0.018978558480739594\n",
            "Epoch 34 loss 0.01897173561155796\n",
            "Epoch 35 loss 0.018972765654325485\n",
            "Epoch 36 loss 0.018979623913764954\n",
            "Epoch 37 loss 0.01897687464952469\n",
            "Epoch 38 loss 0.018969403579831123\n",
            "Epoch 39 loss 0.01897028088569641\n",
            "Epoch 40 loss 0.01897219568490982\n",
            "Epoch 41 loss 0.018971534445881844\n",
            "Epoch 42 loss 0.01897088810801506\n",
            "Epoch 43 loss 0.018968794494867325\n",
            "Epoch 44 loss 0.018967168405652046\n",
            "Epoch 45 loss 0.01896965317428112\n",
            "Epoch 46 loss 0.018970493227243423\n",
            "Epoch 47 loss 0.01896744780242443\n",
            "Epoch 48 loss 0.01896670274436474\n",
            "Epoch 49 loss 0.018967635929584503\n",
            "Epoch 50 loss 0.018967676907777786\n",
            "Epoch 51 loss 0.018967827782034874\n",
            "Epoch 52 loss 0.018967173993587494\n",
            "Epoch 53 loss 0.01896641217172146\n",
            "Epoch 54 loss 0.018967149779200554\n",
            "Epoch 55 loss 0.0189670342952013\n",
            "Epoch 56 loss 0.018966156989336014\n",
            "Epoch 57 loss 0.018966443836688995\n",
            "Epoch 58 loss 0.018966885283589363\n",
            "Epoch 59 loss 0.018966730684041977\n",
            "Epoch 60 loss 0.01896650157868862\n",
            "Epoch 61 loss 0.01896587759256363\n",
            "Epoch 62 loss 0.018966127187013626\n",
            "Epoch 63 loss 0.018966328352689743\n",
            "Epoch 64 loss 0.018965980038046837\n",
            "Epoch 65 loss 0.01896611787378788\n",
            "Epoch 66 loss 0.018966421484947205\n",
            "Epoch 67 loss 0.0189663115888834\n",
            "Epoch 68 loss 0.018966209143400192\n",
            "Epoch 69 loss 0.01896599680185318\n",
            "Epoch 70 loss 0.01896592602133751\n",
            "Epoch 71 loss 0.018965929746627808\n",
            "Epoch 72 loss 0.018965676426887512\n",
            "Epoch 73 loss 0.018965667113661766\n",
            "Epoch 74 loss 0.018965814262628555\n",
            "Epoch 75 loss 0.01896580494940281\n",
            "Epoch 76 loss 0.018965836614370346\n",
            "Epoch 77 loss 0.01896597072482109\n",
            "Epoch 78 loss 0.018966207280755043\n",
            "Epoch 79 loss 0.018966523930430412\n",
            "Epoch 80 loss 0.018966758623719215\n",
            "Epoch 81 loss 0.018967097625136375\n",
            "Epoch 82 loss 0.0189670380204916\n",
            "Epoch 83 loss 0.01896657422184944\n",
            "Epoch 84 loss 0.01896592229604721\n",
            "Epoch 85 loss 0.018965601921081543\n",
            "Epoch 86 loss 0.018965745344758034\n",
            "Epoch 87 loss 0.01896613836288452\n",
            "Epoch 88 loss 0.018966343253850937\n",
            "Epoch 89 loss 0.01896621286869049\n",
            "Epoch 90 loss 0.018965832889080048\n",
            "Epoch 91 loss 0.018965553492307663\n",
            "Epoch 92 loss 0.018965620547533035\n",
            "Epoch 93 loss 0.018965845927596092\n",
            "Epoch 94 loss 0.01896599493920803\n",
            "Epoch 95 loss 0.01896596886217594\n",
            "Epoch 96 loss 0.018965762108564377\n",
            "Epoch 97 loss 0.018965575844049454\n",
            "Epoch 98 loss 0.018965523689985275\n",
            "Epoch 99 loss 0.01896561123430729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [\"Good batting by England\"]\n"
      ],
      "metadata": {
        "id": "48oYf_-pQYf1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = vectorizer.transform(sample).toarray()\n"
      ],
      "metadata": {
        "id": "6tc9DkM8RY2H"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXUYc8d-RZpA",
        "outputId": "47ef9d79-e63d-4597-cab8-02aec0ca21d8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(sample).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhDLC-q-RdcZ",
        "outputId": "5b6f0156-9753-475c-deba-affb330c203f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = model(torch.from_numpy(sample).float())\n",
        "sentiment\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA7zQCUzRiIw",
        "outputId": "8f07190b-b0ad-4f14-f107-03eb734c0922"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1006, -0.4045]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = [\"bad performance by India in the match\"]"
      ],
      "metadata": {
        "id": "aK1gQaDcR0QC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = vectorizer.transform(sample2).toarray()\n"
      ],
      "metadata": {
        "id": "C7obj-DYSH3T"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment2 = model(torch.from_numpy(sample2).float())\n",
        "sentiment2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP8rQ9rqSKnV",
        "outputId": "fee4fd8f-f687-4ac4-ca73-0d5cce491afa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.0000, -30.1357]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhNIuUCgSO1r",
        "outputId": "c0a47092-571b-4022-a440-5447774ff396"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc1.weight',\n",
              "              tensor([[ 0.0589,  0.0423, -0.0321,  ..., -0.0029,  0.0840,  0.2080],\n",
              "                      [ 0.1140,  0.0314,  0.1418,  ..., -0.0462,  0.0452, -0.1347],\n",
              "                      [ 0.0694,  0.0059,  0.1361,  ..., -0.0841,  0.0932, -0.1137],\n",
              "                      ...,\n",
              "                      [-0.0187,  0.0540, -0.0359,  ...,  0.0423,  0.0159,  0.0411],\n",
              "                      [-0.0186,  0.0492,  0.0447,  ..., -0.0065, -0.1433, -0.0520],\n",
              "                      [ 0.1272,  0.0665,  0.0948,  ...,  0.1060,  0.0661,  0.2140]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([ 4.5164e-02, -2.2066e-02, -3.6680e-02, -4.9540e-02, -9.4778e-02,\n",
              "                      -6.2344e-02, -2.9930e-02, -8.3484e-02,  4.6847e-02,  8.6610e-03,\n",
              "                       7.6172e-02, -4.6041e-02, -5.5573e-02, -3.5723e-02, -5.3950e-02,\n",
              "                      -3.0232e-02, -6.9785e-02,  6.2646e-02, -1.0783e-01, -3.9931e-03,\n",
              "                      -4.3449e-02, -7.0220e-02, -1.8580e-02,  5.5303e-02, -1.8459e-02,\n",
              "                      -4.8516e-02,  6.4832e-02,  3.9153e-02, -4.9841e-02, -5.1841e-02,\n",
              "                      -1.6427e-03, -1.5287e-02, -4.0077e-02, -6.5976e-02,  1.4285e-02,\n",
              "                      -5.2221e-02,  7.3934e-03, -1.4468e-01, -4.3399e-02,  5.4791e-02,\n",
              "                      -5.3756e-02, -6.4952e-02,  5.2543e-02, -3.3224e-02, -6.2410e-02,\n",
              "                       5.0830e-02, -8.2422e-02, -8.0818e-02, -4.9122e-02, -6.5603e-02,\n",
              "                       4.8920e-02,  5.0951e-02,  4.9059e-02,  1.0288e-03, -1.0623e-02,\n",
              "                       3.7461e-02, -5.2190e-02, -1.8488e-02, -4.5522e-03, -1.3497e-02,\n",
              "                       4.2951e-02, -2.8887e-02, -3.0355e-02,  4.3114e-03, -4.4896e-02,\n",
              "                      -8.8234e-02, -7.8309e-02, -1.0054e-02, -3.0305e-02, -4.1748e-02,\n",
              "                      -2.4539e-02, -3.2942e-02, -1.7982e-02, -5.9733e-02, -5.4411e-02,\n",
              "                      -4.3747e-02, -7.1430e-02,  4.5140e-02, -2.3029e-02, -6.4157e-02,\n",
              "                       1.0140e-02,  5.8881e-02,  4.3850e-03,  8.2379e-02,  3.9035e-02,\n",
              "                       6.3631e-02,  4.8002e-03,  5.1616e-02, -3.1138e-02,  5.1303e-02,\n",
              "                       3.8425e-02, -1.4768e-02,  7.6093e-02, -1.2568e-03, -4.5262e-02,\n",
              "                      -3.1300e-02, -1.0692e-01, -1.3544e-03, -4.8552e-02, -8.5497e-02,\n",
              "                      -7.3092e-02, -2.1431e-02,  3.2576e-02, -4.7070e-02, -3.2852e-02,\n",
              "                      -1.4232e-01, -2.1987e-02, -1.5302e-02,  5.7331e-02,  5.3263e-02,\n",
              "                      -2.6280e-02, -2.7668e-02, -7.7245e-02, -3.1821e-02, -5.5333e-03,\n",
              "                      -1.7555e-02,  3.7049e-02,  4.0366e-02, -4.4026e-02, -7.5595e-02,\n",
              "                      -1.3925e-01, -1.5000e-03,  3.4226e-02, -2.1514e-02, -1.8267e-02,\n",
              "                       5.8261e-03, -5.3900e-02,  4.0590e-02, -4.0310e-02,  4.5626e-02,\n",
              "                      -1.7348e-02,  4.7698e-02, -2.4474e-02, -1.6898e-02, -7.7945e-02,\n",
              "                      -1.6813e-02,  5.3782e-02, -4.7956e-02, -8.9082e-02, -3.3444e-02,\n",
              "                      -2.4634e-02, -7.6475e-03, -2.7533e-02, -6.2812e-02, -5.4366e-02,\n",
              "                      -3.9820e-02, -5.2205e-02,  2.7323e-02,  8.6964e-03, -3.5856e-02,\n",
              "                      -2.9350e-02,  4.9367e-02, -8.4423e-02, -8.8948e-02,  5.4881e-02,\n",
              "                       5.3900e-02, -4.4479e-03,  6.3738e-02, -2.8295e-02,  4.6485e-02,\n",
              "                      -5.5070e-02, -4.5893e-02,  1.7784e-02,  4.5764e-02,  5.4780e-02,\n",
              "                       5.5437e-02, -2.0495e-02, -2.0180e-02, -8.4406e-02, -3.9422e-02,\n",
              "                      -4.7763e-02, -5.0893e-02,  3.4897e-02, -5.8488e-02,  7.1217e-02,\n",
              "                      -4.0294e-04,  8.6257e-03,  1.9488e-02, -3.7858e-02, -6.3358e-02,\n",
              "                       4.4522e-02, -5.4632e-02, -5.2506e-02, -2.7629e-02,  5.1156e-02,\n",
              "                       4.2611e-02, -8.9986e-03, -3.9775e-02, -5.3681e-02, -8.2700e-02,\n",
              "                      -2.5624e-02, -4.8116e-03,  4.9226e-02,  4.9476e-02, -4.6210e-02,\n",
              "                      -1.0093e-01, -5.3596e-02, -4.9127e-02, -5.0710e-02,  4.0966e-03,\n",
              "                      -3.7387e-02, -2.4472e-02, -1.1110e-01,  5.9564e-02,  6.4468e-02,\n",
              "                       5.9431e-02,  1.1918e-03, -9.8465e-02,  6.9781e-02,  1.4713e-02,\n",
              "                       1.0321e-02,  2.3359e-02, -7.4353e-02, -4.8324e-02, -9.1472e-02,\n",
              "                       6.6275e-02, -1.7297e-02, -5.1144e-02,  2.3046e-04, -1.0139e-01,\n",
              "                      -4.8037e-02, -1.4871e-02, -4.5328e-02,  2.6162e-03, -4.6600e-02,\n",
              "                       3.2633e-02, -8.7482e-02,  2.7313e-02, -8.6526e-03,  1.2213e-02,\n",
              "                      -3.9202e-02, -4.8927e-02,  1.2915e-03, -2.2414e-02,  9.7286e-03,\n",
              "                      -4.9314e-02, -1.1158e-01, -6.7583e-02,  2.5510e-02, -1.6318e-02,\n",
              "                      -1.7914e-02, -6.2131e-02,  4.6418e-02,  2.7981e-02,  4.1103e-02,\n",
              "                       6.3066e-02,  4.6172e-02,  2.4786e-02, -4.2173e-02, -3.0086e-02,\n",
              "                      -1.0860e-01,  5.0567e-02,  4.6510e-02,  1.6663e-02, -8.8151e-02,\n",
              "                       4.3908e-02,  5.7298e-02,  1.0305e-01, -4.8802e-02, -6.7833e-02,\n",
              "                      -4.3518e-02, -6.0979e-02,  6.7897e-03,  6.3174e-02,  6.4069e-02,\n",
              "                      -4.8946e-02,  5.2447e-02, -1.4478e-02, -2.7740e-02, -5.2391e-02,\n",
              "                       1.0209e-03, -5.3569e-02, -2.9156e-02, -3.5324e-02, -5.5213e-02,\n",
              "                      -1.3177e-02,  3.0712e-02,  5.1760e-02, -1.0033e-01,  5.4294e-02,\n",
              "                       4.9156e-02, -4.5353e-02, -3.9588e-02,  4.7035e-02, -5.4751e-02,\n",
              "                       4.6188e-02, -1.0488e-01, -4.9734e-02,  3.9816e-02,  1.5317e-02,\n",
              "                       4.2110e-02,  4.4963e-02,  1.8741e-03, -1.8478e-03, -4.5616e-02,\n",
              "                      -5.9760e-02, -1.8478e-02,  8.2405e-03, -3.8157e-02, -1.2544e-02,\n",
              "                       4.7244e-02,  4.3074e-02,  4.0519e-02, -5.0257e-03, -7.3457e-02,\n",
              "                      -5.2801e-02,  1.6612e-02,  3.3328e-04, -4.5896e-02,  1.2235e-02,\n",
              "                       1.9249e-02,  4.2193e-02, -1.0407e-02, -3.7772e-02,  8.5191e-03,\n",
              "                      -2.9306e-02, -1.3239e-01,  5.3974e-02,  3.4941e-02,  4.4680e-02,\n",
              "                      -1.4170e-01, -1.8046e-02, -3.0004e-02, -5.0989e-02, -1.3094e-02,\n",
              "                      -3.6662e-04, -2.7858e-02,  4.8071e-02, -5.5212e-02,  4.4899e-02,\n",
              "                       4.1516e-02, -2.8696e-02, -2.9937e-02, -1.2550e-01, -9.0275e-02,\n",
              "                      -1.8361e-02, -3.3791e-02, -7.9336e-02, -1.7945e-02, -7.8172e-03,\n",
              "                       5.4717e-02, -4.1420e-02,  8.3093e-02,  6.3133e-02,  4.9132e-02,\n",
              "                      -9.1255e-02,  1.0357e-03,  6.1937e-02, -4.3458e-02, -3.0229e-02,\n",
              "                      -2.1750e-02, -2.6945e-02, -8.4080e-02,  5.4713e-02, -2.4828e-02,\n",
              "                       1.7452e-02,  8.1783e-03, -5.4450e-02, -5.1119e-02, -3.7234e-03,\n",
              "                      -5.3421e-02, -2.4555e-02, -7.5390e-02, -3.5654e-02,  4.5203e-02,\n",
              "                      -5.1555e-02, -1.8771e-02, -7.1607e-04,  1.0213e-02,  4.6447e-02,\n",
              "                      -3.0665e-03,  1.1721e-02, -1.2313e-02, -2.2026e-02, -2.8435e-02,\n",
              "                      -2.3500e-02,  1.6912e-02, -5.0910e-02, -4.8280e-02,  4.9231e-02,\n",
              "                      -6.6266e-02,  5.3938e-02, -4.2322e-03, -1.0807e-02, -3.1828e-02,\n",
              "                      -4.6375e-02, -5.0268e-02, -2.0720e-02,  4.9849e-02, -2.2935e-02,\n",
              "                      -5.8117e-02, -2.6804e-02,  5.0788e-02, -7.7929e-02, -3.1593e-02,\n",
              "                      -3.7409e-02, -1.7895e-02,  4.2453e-02, -7.5499e-02,  5.3913e-02,\n",
              "                      -1.0558e-01, -1.0931e-02, -2.0448e-02,  4.1294e-02,  5.8521e-02,\n",
              "                      -1.3730e-02, -9.0265e-02, -4.5295e-02,  2.7132e-02,  2.2184e-02,\n",
              "                       5.8832e-02, -3.9862e-02, -2.3955e-02, -4.8234e-02,  5.5651e-02,\n",
              "                      -3.2289e-02, -1.1481e-04,  9.8626e-04,  4.6175e-04,  3.4258e-03,\n",
              "                      -5.8242e-02,  2.8102e-03, -1.0612e-02,  1.0526e-02,  2.9979e-03,\n",
              "                       4.9195e-02, -1.0161e-02, -7.9231e-02, -1.2919e-02, -1.9705e-02,\n",
              "                       5.3270e-03, -3.5824e-02, -2.9881e-02, -4.4336e-02, -6.4449e-03,\n",
              "                       5.0804e-02, -2.6870e-02, -2.6065e-02, -3.0598e-02,  5.2123e-02,\n",
              "                       4.8988e-02, -8.8115e-02,  4.8533e-02, -5.3253e-02, -7.2561e-02,\n",
              "                       5.4576e-02, -4.1404e-02,  6.9974e-02, -2.4145e-02,  4.9074e-02,\n",
              "                       2.9804e-02,  4.7837e-02, -3.6269e-02,  2.1659e-02, -6.1704e-02,\n",
              "                      -1.0835e-02,  1.6541e-02, -4.1611e-02, -8.7231e-02, -1.3787e-02,\n",
              "                       5.5066e-02, -2.4266e-02,  7.8304e-03, -2.2677e-02, -8.3293e-02,\n",
              "                      -2.6681e-02, -5.1421e-02, -6.7499e-02, -6.0259e-03, -4.3902e-02,\n",
              "                       5.5870e-02, -8.6106e-02,  5.4395e-02,  4.9841e-04,  2.2953e-02,\n",
              "                      -1.9513e-02,  4.2435e-02, -7.5751e-02,  2.9901e-02,  4.8352e-02,\n",
              "                       3.9066e-02, -2.8765e-02, -2.7596e-02,  6.0992e-02, -8.0007e-03,\n",
              "                       5.7593e-02, -1.2558e-01,  4.7797e-02,  1.5581e-01, -9.8162e-02,\n",
              "                      -7.8110e-02, -2.3286e-02, -7.9798e-02,  2.6318e-02, -2.9532e-02,\n",
              "                      -8.0877e-02, -2.5084e-02, -4.8735e-02, -3.4833e-02,  5.4908e-02])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[-0.0157, -0.0515, -0.0419,  ..., -0.0776, -0.1506, -0.1000],\n",
              "                      [-0.0412, -0.0162, -0.0661,  ..., -0.0790, -0.1423,  0.0264],\n",
              "                      [-0.0416, -0.0358, -0.0782,  ..., -0.0689, -0.1437, -0.0220],\n",
              "                      ...,\n",
              "                      [ 0.0193,  0.0569,  0.0112,  ..., -0.0612,  0.0027,  0.0727],\n",
              "                      [-0.1139,  0.0037, -0.0338,  ...,  0.0631, -0.0030, -0.0394],\n",
              "                      [ 0.0172, -0.0885, -0.0780,  ..., -0.0388, -0.1120, -0.0440]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([-3.9161e-02,  9.7565e-02,  1.1068e-02,  5.8772e-02, -5.7043e-03,\n",
              "                      -6.7873e-03, -8.6318e-02, -4.2876e-02, -1.1578e-02, -7.4546e-02,\n",
              "                      -3.2364e-02, -1.1233e-01, -1.7413e-02,  7.1904e-02, -1.0877e-01,\n",
              "                       8.5374e-02, -1.5833e-02, -5.7480e-02, -3.1448e-02, -9.5172e-03,\n",
              "                      -2.6718e-02, -4.6727e-02,  6.5362e-02, -1.3059e-01, -2.5780e-02,\n",
              "                       5.8694e-02, -2.8201e-02, -3.0476e-02,  4.7058e-02, -4.3284e-02,\n",
              "                      -2.6468e-02, -8.2382e-02, -3.3965e-02, -4.7668e-02,  7.6420e-02,\n",
              "                      -5.2796e-02, -2.5624e-02, -1.5438e-02, -3.2644e-02, -1.1829e-01,\n",
              "                      -3.2577e-02,  6.9740e-03, -4.1563e-02,  4.8286e-02,  9.9842e-02,\n",
              "                       5.5708e-04, -5.0312e-02, -2.7033e-02, -3.3452e-02,  6.6364e-02,\n",
              "                      -1.0198e-01, -3.9304e-02, -3.8722e-02,  6.0113e-02,  3.1877e-02,\n",
              "                      -5.6199e-02, -3.9301e-02,  2.8936e-02, -5.1416e-02, -2.8115e-02,\n",
              "                      -1.2250e-01, -6.5883e-02,  8.1963e-03, -3.1561e-02, -6.0562e-02,\n",
              "                      -4.7825e-02,  5.1544e-02, -1.1649e-01, -3.4109e-02,  4.8798e-02,\n",
              "                      -7.7504e-02, -1.2517e-02, -8.8147e-02, -2.6983e-03,  1.1132e-02,\n",
              "                       4.0813e-02, -2.2971e-02, -3.4980e-02,  6.3525e-02, -5.2277e-02,\n",
              "                      -7.4659e-02, -4.3896e-02, -4.7801e-02,  5.6354e-03, -1.1208e-01,\n",
              "                      -2.5223e-02, -4.0358e-02, -4.7272e-02, -3.0880e-02, -3.8391e-02,\n",
              "                      -4.2692e-02, -7.2836e-02, -2.8915e-02,  4.6791e-02, -2.4006e-02,\n",
              "                      -1.2065e-01, -4.7299e-02, -3.8483e-02, -3.7124e-02, -3.8658e-02,\n",
              "                       3.4082e-03,  7.8837e-02, -4.2521e-02,  2.6645e-02,  8.4723e-02,\n",
              "                      -5.3129e-02, -3.5584e-02, -2.2526e-02, -4.1902e-02, -2.4799e-02,\n",
              "                       1.3209e-02, -3.3483e-02,  5.8553e-02, -5.5160e-02, -3.2854e-02,\n",
              "                       8.0880e-03, -2.0609e-02,  5.3841e-02, -1.0597e-01, -5.2348e-02,\n",
              "                       5.8158e-02, -6.3717e-03,  7.3464e-02, -1.2735e-01, -3.2136e-02,\n",
              "                       3.1399e-02, -1.6219e-02,  9.4787e-02,  6.6205e-03,  7.2074e-02,\n",
              "                      -8.2160e-02, -3.5379e-02, -4.4172e-02, -7.0130e-02, -1.0743e-01,\n",
              "                       5.3240e-02, -4.1035e-02, -1.2026e-03,  9.3595e-02,  7.1204e-02,\n",
              "                      -1.2558e-02,  7.9520e-02, -5.9322e-02, -5.4669e-02,  6.1086e-02,\n",
              "                      -1.2841e-02, -5.6734e-03, -1.0770e-02, -9.8431e-02, -6.2473e-02,\n",
              "                      -1.1526e-01, -1.3596e-01, -2.4301e-02, -9.2168e-02, -4.5895e-03,\n",
              "                      -9.7391e-02,  3.8616e-02, -2.6795e-02, -3.6654e-02,  1.9583e-02,\n",
              "                       3.7013e-02,  5.9649e-03, -1.3098e-01, -1.0553e-01, -1.5469e-02,\n",
              "                      -1.5301e-01,  3.4177e-02, -1.7587e-02, -2.3042e-02, -3.8278e-03,\n",
              "                      -5.4015e-03,  1.2733e-02,  6.1236e-02, -9.7788e-02, -4.1455e-02,\n",
              "                      -7.2654e-02, -1.6946e-04,  2.1349e-02, -3.5976e-03, -4.7347e-02,\n",
              "                      -1.2034e-01,  2.0155e-02, -2.8470e-02, -5.0957e-02, -3.3353e-02,\n",
              "                      -6.3772e-02,  9.7076e-02, -4.1734e-02, -5.4115e-03, -5.2800e-03,\n",
              "                      -2.0520e-02, -9.1628e-03,  2.0633e-03, -3.5203e-02,  1.2157e-02,\n",
              "                       6.0561e-02, -3.5395e-02, -5.1434e-02, -1.2560e-02, -1.7682e-02,\n",
              "                      -1.2245e-02,  4.5097e-02, -1.9702e-02,  4.5865e-03,  1.4686e-02,\n",
              "                      -1.2917e-01, -3.0118e-02, -7.8189e-02, -2.0293e-02, -1.2280e-02,\n",
              "                       1.2686e-03, -1.5413e-03, -6.1113e-02, -9.8295e-02, -3.0553e-02,\n",
              "                       3.7642e-03, -5.4901e-02, -3.3678e-02, -8.9029e-02, -2.8279e-02,\n",
              "                      -6.5692e-02, -1.1354e-01, -7.1721e-02, -4.7515e-02, -8.9075e-02,\n",
              "                      -8.0483e-02, -9.0054e-02, -3.7181e-02, -3.8318e-02, -1.1530e-01,\n",
              "                      -1.3989e-02, -4.9556e-02, -8.1770e-02,  7.9872e-02, -3.8919e-02,\n",
              "                      -9.9549e-02, -1.7634e-02, -6.5202e-02, -5.0734e-02, -2.0545e-02,\n",
              "                      -4.4139e-02, -3.7354e-02, -1.9495e-02,  3.2479e-03, -1.6527e-02,\n",
              "                       4.4675e-02, -3.5858e-02, -8.2367e-03,  5.2927e-03, -1.7599e-02,\n",
              "                       6.7995e-02, -4.6741e-02, -5.4911e-02, -9.2520e-02, -5.2610e-02,\n",
              "                      -4.2130e-02, -3.3676e-02,  2.6896e-02, -3.6431e-02, -1.0077e-02,\n",
              "                      -3.2514e-02, -3.3561e-03,  3.3452e-02, -6.4796e-03, -1.0624e-01,\n",
              "                      -3.7865e-02, -1.0316e-01, -3.2444e-02,  5.9582e-02,  5.3351e-02,\n",
              "                      -9.1325e-02, -4.1513e-02,  6.5031e-02, -3.6499e-02, -8.4069e-02,\n",
              "                       4.8111e-03, -1.1694e-01, -8.2371e-02, -1.9985e-02, -4.7133e-02,\n",
              "                      -1.5045e-01, -5.2708e-02, -7.9895e-02, -5.8681e-02,  4.1261e-02,\n",
              "                      -8.8613e-02, -4.3299e-02, -1.6974e-02, -2.9056e-02,  4.4882e-03,\n",
              "                      -1.5019e-02, -5.8806e-02, -3.9850e-02, -3.0836e-02, -5.0935e-02,\n",
              "                      -7.7775e-03, -6.4607e-02, -3.8574e-02,  6.8515e-02, -3.0551e-02,\n",
              "                      -6.7157e-02, -5.9057e-03, -7.2186e-03,  3.6088e-03, -1.1360e-02,\n",
              "                      -3.9463e-02, -4.6641e-02,  6.0152e-02,  4.8291e-02, -8.8049e-02,\n",
              "                       8.6641e-02, -4.0421e-02, -3.4271e-02, -4.5754e-02, -2.2627e-02,\n",
              "                       7.1391e-02, -6.2362e-03, -3.8034e-02,  3.2335e-02, -3.5252e-02,\n",
              "                      -5.5395e-02, -2.1989e-02,  7.8925e-03, -4.4162e-02, -3.8306e-02,\n",
              "                       3.3636e-02, -3.3427e-02,  1.0269e-01, -6.9040e-02, -5.7585e-02,\n",
              "                      -1.0403e-01, -6.4445e-02, -2.1363e-02, -4.8708e-02, -2.5748e-02,\n",
              "                       1.0418e-01, -7.0863e-02, -3.0337e-02,  4.0055e-03, -2.5856e-02,\n",
              "                       1.9951e-03,  7.8372e-02, -4.4307e-02,  8.5259e-02, -1.3189e-01,\n",
              "                      -4.6748e-03, -2.5476e-02,  4.0062e-02, -1.1111e-01, -1.3265e-01,\n",
              "                      -8.6380e-03,  4.5361e-02, -3.7665e-02, -1.0969e-02, -4.3514e-02,\n",
              "                      -5.7566e-02, -3.8263e-03, -9.8132e-03, -2.9107e-02, -1.3162e-01,\n",
              "                      -2.3799e-02,  1.5056e-02, -2.9385e-02,  3.7514e-02, -2.9350e-02,\n",
              "                      -4.7638e-02, -1.7707e-02, -5.2093e-02, -8.3837e-03, -1.6313e-02,\n",
              "                      -3.6616e-02, -2.3174e-02, -3.0219e-02, -1.6889e-02, -5.7556e-02,\n",
              "                       7.0820e-02, -3.3455e-02, -1.9122e-02,  1.6531e-01, -1.0509e-02,\n",
              "                      -1.0675e-02, -9.5880e-02,  4.6454e-02, -2.0038e-03,  3.6958e-02,\n",
              "                      -4.0707e-02, -2.9203e-02, -2.0493e-02,  1.4972e-03,  7.4803e-02,\n",
              "                      -6.3303e-03, -3.4689e-02, -1.6119e-02, -1.1088e-01, -6.1458e-03,\n",
              "                      -4.2592e-02, -1.4799e-02, -6.7909e-03,  2.9560e-02, -2.6285e-02,\n",
              "                      -5.5560e-02, -1.0652e-02, -1.1386e-01,  3.8359e-02, -1.0304e-01,\n",
              "                      -9.1569e-02, -4.6490e-02,  1.0085e-02, -2.2047e-02, -5.3821e-02,\n",
              "                      -1.1493e-02, -9.9652e-02, -1.0912e-01, -1.0760e-01,  6.9958e-02,\n",
              "                      -2.2678e-02, -6.3755e-03, -6.8456e-02,  6.1772e-02,  1.0212e-01,\n",
              "                       2.5523e-03, -2.5939e-02, -3.9481e-02,  7.2704e-02, -3.9185e-02,\n",
              "                       1.2978e-02, -1.0335e-01, -8.9278e-03, -8.1801e-03, -2.3387e-02,\n",
              "                      -5.1830e-02,  1.4895e-02, -9.2538e-03, -2.3050e-02, -1.1869e-02,\n",
              "                       6.8331e-02, -2.6027e-02, -3.7618e-02, -3.2794e-02, -3.5280e-03,\n",
              "                      -2.4740e-02,  1.2052e-02,  6.1534e-02,  5.9548e-02, -1.2557e-02,\n",
              "                      -3.3555e-02, -5.5044e-02, -4.0017e-02, -2.7825e-05, -3.6791e-02,\n",
              "                      -1.9036e-02, -6.3574e-02, -1.0606e-01,  5.6721e-02, -2.6788e-02,\n",
              "                       4.7776e-02, -1.0314e-01,  1.1123e-03, -7.5919e-02, -2.8620e-02,\n",
              "                      -1.0535e-01, -6.4491e-02, -9.3240e-02, -8.3605e-03,  5.4453e-03,\n",
              "                      -7.5696e-03, -1.3098e-01, -8.8683e-02,  8.7730e-02, -1.2756e-01,\n",
              "                      -6.8434e-03, -3.7373e-03, -8.9879e-02,  5.8330e-02, -1.1738e-02,\n",
              "                       9.8962e-02,  1.4491e-02, -8.9728e-02, -9.5730e-02, -4.3991e-02,\n",
              "                      -6.8935e-02,  7.2519e-02, -5.2438e-02,  6.9999e-02,  3.8174e-03,\n",
              "                       3.5708e-02, -1.0890e-01, -1.4756e-02,  6.3159e-02, -4.9030e-02,\n",
              "                       3.5007e-02, -1.1246e-02,  4.5292e-02, -3.7588e-02, -2.1602e-02,\n",
              "                      -3.6449e-02, -3.3005e-02,  4.6934e-02, -1.4367e-02, -2.1343e-02])),\n",
              "             ('fc3.weight',\n",
              "              tensor([[-5.0107e-02, -8.2792e-02, -8.0968e-02, -2.8508e-01,  1.4820e-02,\n",
              "                        7.6534e-03,  1.4774e-02,  2.1150e-02, -8.2487e-02, -5.7596e-02,\n",
              "                       -3.8947e-02, -3.6079e-02, -5.7394e-02, -6.4791e-02, -4.6666e-02,\n",
              "                       -7.3232e-02, -4.9909e-03, -6.0256e-02, -2.0815e-03,  3.3313e-02,\n",
              "                        2.7173e-02,  4.3151e-02, -1.3804e-02, -5.5456e-02,  4.3370e-02,\n",
              "                       -4.9270e-02,  1.4252e-02, -4.9490e-03,  1.5972e-02, -6.9001e-03,\n",
              "                       -2.2537e-02, -7.0554e-02, -1.8594e-03, -7.2528e-02, -5.5765e-02,\n",
              "                       -7.9715e-02, -3.1736e-03, -8.8912e-02,  1.8092e-02, -7.2891e-02,\n",
              "                       -9.8873e-04,  9.0562e-03, -1.1841e-02,  7.6356e-02, -9.7002e-02,\n",
              "                        8.3195e-03, -4.8797e-02,  1.9324e-02, -5.7633e-02, -6.9857e-02,\n",
              "                       -6.4369e-02, -6.5549e-02, -2.9063e-02, -3.5596e-02, -4.1340e-02,\n",
              "                       -2.7111e-02, -4.1224e-02, -6.6660e-02, -6.5556e-02, -6.5811e-02,\n",
              "                        2.3478e-01, -1.1428e-02,  4.3691e-02,  5.1234e-03, -8.7135e-02,\n",
              "                        1.3405e-02, -5.1484e-02, -4.6094e-02, -1.7743e-01, -3.2574e-02,\n",
              "                       -1.8764e-02, -1.2113e-02,  1.1931e-02, -2.1766e-02, -7.6108e-02,\n",
              "                       -6.8803e-02, -3.0320e-02, -2.6179e-03, -3.4851e-02, -5.2502e-02,\n",
              "                        1.0638e-03, -7.3027e-02,  9.8924e-04, -6.3531e-02, -3.6615e-03,\n",
              "                        1.6134e-01,  2.4428e-03,  3.4352e-02,  1.5189e-02,  2.4452e-02,\n",
              "                        3.2839e-02, -5.4777e-02, -1.2334e-02, -8.8700e-02,  2.8228e-02,\n",
              "                        1.5763e-01, -1.7990e-02, -9.6228e-03,  1.5540e-02,  1.8991e-02,\n",
              "                       -7.6729e-03, -8.5826e-02, -8.4818e-02, -4.5450e-02, -7.3703e-02,\n",
              "                        2.0106e-02,  2.0952e-02,  2.2800e-02,  1.6647e-02, -9.0425e-02,\n",
              "                       -4.7781e-02, -1.7780e-02, -4.1651e-02,  2.3832e-02, -4.1826e-02,\n",
              "                       -2.7944e-02,  3.1053e-02, -5.4482e-02, -5.4342e-02, -1.1818e-02,\n",
              "                       -3.4527e-02,  1.3385e-02,  1.0650e-01, -3.6836e-02,  2.3459e-02,\n",
              "                       -9.0620e-02,  3.7328e-02, -1.1477e-01, -3.8315e-03, -4.3773e-02,\n",
              "                        4.8122e-03,  2.1391e-03, -3.5121e-02, -1.7311e-02, -2.1859e-02,\n",
              "                        1.1845e-01, -1.0344e-02, -3.1966e-03, -2.7387e-02, -4.2959e-02,\n",
              "                        1.4902e-03, -6.9389e-02,  2.4107e-03,  7.0316e-02, -4.8028e-02,\n",
              "                        2.7280e-02, -7.4619e-03, -5.6979e-03, -5.2991e-02, -2.8015e-02,\n",
              "                       -5.9189e-02, -2.8189e-02,  3.6330e-02,  5.1704e-02,  4.3955e-02,\n",
              "                       -4.4125e-02, -1.7995e-01, -1.5377e-02, -2.5016e-02, -1.8042e-02,\n",
              "                       -4.1687e-02,  5.5019e-02, -7.9830e-02, -6.7834e-02, -5.6333e-02,\n",
              "                        8.6557e-02, -9.9188e-02, -1.3738e-02,  1.3924e-02,  1.0396e-02,\n",
              "                       -1.1929e-02,  2.2011e-02, -6.9273e-02, -7.9646e-02, -9.1686e-02,\n",
              "                        3.6398e-02,  1.2846e-02, -9.2085e-02, -5.6349e-02,  2.0534e-04,\n",
              "                        7.0514e-03, -6.7556e-02,  4.2010e-02, -2.6382e-02, -3.2699e-02,\n",
              "                        9.3255e-03,  1.5349e-01, -5.3499e-02,  1.1560e-02, -7.5085e-02,\n",
              "                       -1.3912e-02, -5.1572e-02,  1.0876e-02,  3.9980e-02, -3.0581e-01,\n",
              "                       -1.0297e-01,  3.2829e-02, -9.4844e-02, -5.9674e-02, -6.8655e-02,\n",
              "                        6.3763e-03, -2.2748e-02, -1.7518e-02,  6.6632e-03, -5.6763e-02,\n",
              "                       -1.3817e-02,  9.4580e-03, -4.0054e-02, -1.3961e-02, -3.6494e-02,\n",
              "                       -4.2102e-02,  1.4506e-02,  2.8396e-02, -4.0046e-02, -6.1949e-02,\n",
              "                        6.1321e-03, -4.6186e-02, -2.4310e-02, -5.4628e-02, -1.6065e-02,\n",
              "                       -3.3288e-02, -2.7578e-02, -4.6148e-02, -3.7102e-02, -4.3226e-02,\n",
              "                       -2.5255e-02, -4.4755e-02, -2.4377e-02, -1.8592e-02, -4.2164e-02,\n",
              "                        2.3455e-03,  1.2011e-02,  4.8274e-03, -6.4448e-02, -8.2440e-03,\n",
              "                        1.9397e-01, -2.0296e-02, -1.9283e-02,  1.2753e-02, -2.0430e-02,\n",
              "                        2.6763e-02,  9.7176e-03,  3.6454e-02,  1.3111e-02,  1.6853e-02,\n",
              "                       -8.2144e-02,  1.3343e-02,  9.3533e-03, -2.3305e-02,  3.2184e-02,\n",
              "                       -3.8475e-02, -2.2691e-02, -8.8463e-03, -7.6134e-02, -6.6418e-02,\n",
              "                        1.7149e-02,  2.5077e-02, -1.3272e-02,  3.4928e-02,  1.1936e-01,\n",
              "                        1.3143e-03, -7.7554e-03, -1.8248e-02, -1.9359e-02, -8.5087e-02,\n",
              "                       -1.8122e-02, -4.6573e-02,  1.3969e-02, -5.4668e-02, -4.5374e-02,\n",
              "                       -4.2109e-02, -3.5217e-02, -5.5215e-02,  2.9699e-02, -9.4330e-03,\n",
              "                       -4.0216e-02, -1.6526e-02, -4.4599e-02, -2.2448e-02, -3.8793e-02,\n",
              "                        1.2863e-02, -3.3951e-03, -2.9754e-02, -2.6227e-02, -3.3736e-02,\n",
              "                       -8.5831e-02, -6.3929e-02,  7.0887e-03,  3.3010e-03,  3.4796e-02,\n",
              "                        4.2238e-02, -5.8703e-02,  2.6105e-03,  1.9493e-02,  2.1149e-02,\n",
              "                        1.9004e-03, -7.9917e-02, -5.9286e-03, -8.4773e-02, -7.0202e-02,\n",
              "                       -2.1296e-02, -1.9940e-02,  3.8755e-02, -8.4565e-02, -2.7521e-02,\n",
              "                        1.5418e-02, -1.3776e-02, -4.6002e-02, -5.4490e-02, -3.5127e-02,\n",
              "                       -4.6378e-02, -1.3517e-01, -1.0577e-02, -5.3843e-02,  3.7766e-02,\n",
              "                       -5.7907e-02,  1.4063e-02,  1.2315e-02, -2.6889e-02, -2.7468e-02,\n",
              "                       -6.5014e-02, -1.1347e-02,  6.5818e-03, -9.2957e-03,  9.2639e-04,\n",
              "                       -3.4434e-02, -2.0621e-02, -1.0608e-01, -2.8932e-02,  3.0142e-02,\n",
              "                       -6.0600e-02, -6.4150e-02,  1.5243e-02, -1.8464e-02, -5.4380e-02,\n",
              "                       -4.4802e-02, -6.9288e-03,  4.2498e-02, -3.8014e-02, -8.6443e-03,\n",
              "                       -2.3119e-02, -1.0572e-01,  1.6820e-02, -7.0289e-02,  1.0211e-03,\n",
              "                        1.3442e-04,  1.4649e-02, -4.5049e-02, -4.7193e-02, -5.9148e-02,\n",
              "                        1.2554e-02, -3.1465e-02,  5.6353e-03, -9.0733e-02,  1.6765e-03,\n",
              "                        2.0660e-02, -4.1304e-02, -6.5246e-02, -4.2932e-02, -1.8510e-02,\n",
              "                        1.1855e-02, -7.1737e-02, -1.3392e-02, -1.0834e-03,  1.2594e-03,\n",
              "                       -6.8928e-03, -1.4194e-02,  1.3496e-02, -3.8107e-03, -1.1288e-02,\n",
              "                        9.5708e-03,  1.5891e-02,  1.7154e-02, -2.3316e-02, -6.4671e-02,\n",
              "                       -7.5061e-02,  4.0522e-03, -3.4775e-02,  2.3743e-01, -5.2450e-02,\n",
              "                        1.6519e-03,  3.5695e-02, -3.7604e-02, -6.6980e-02, -2.5162e-02,\n",
              "                        8.2246e-03,  3.5136e-03,  8.4980e-03, -2.9681e-03, -3.3986e-02,\n",
              "                        6.6764e-03,  5.3065e-03,  3.4398e-03, -5.6614e-02, -7.2290e-02,\n",
              "                       -2.2904e-01, -2.1357e-02,  1.8636e-02, -5.9046e-02, -3.2964e-02,\n",
              "                       -4.7806e-02, -2.5406e-02, -2.5404e-02, -5.5064e-02, -6.7752e-02,\n",
              "                       -3.1443e-02, -4.2158e-03, -2.6499e-02,  4.8195e-03, -8.0836e-02,\n",
              "                        4.9434e-02, -5.4291e-02,  1.3475e-01,  1.8122e-01, -8.7349e-02,\n",
              "                       -2.7772e-02, -1.0713e-02, -4.1134e-02, -6.7427e-02, -9.2340e-02,\n",
              "                       -1.2843e-02, -2.9782e-02,  2.9237e-02, -3.1480e-01, -6.8457e-03,\n",
              "                       -6.7027e-02,  2.5511e-01,  1.3980e-02,  7.9974e-03, -1.5640e-02,\n",
              "                        1.9400e-02, -4.2423e-02, -1.4638e-02, -2.7405e-02, -5.6005e-03,\n",
              "                       -5.3828e-02, -1.9346e-02, -2.3465e-02,  1.9033e-04, -4.6492e-03,\n",
              "                       -1.7640e-02, -8.4017e-02, -8.5744e-02, -2.7553e-02, -1.9898e-02,\n",
              "                       -2.0141e-02,  4.0072e-03,  1.4256e-02, -4.1082e-02,  1.8107e-02,\n",
              "                        1.1612e-02, -1.4863e-02, -2.6719e-02, -3.4922e-02,  2.9834e-02,\n",
              "                       -7.5882e-02, -5.9711e-02,  1.7638e-01, -4.5580e-02,  2.1178e-02,\n",
              "                       -5.8149e-02, -3.7278e-02, -6.5512e-02, -1.3858e-02, -1.2614e-02,\n",
              "                       -1.8441e-02, -5.9248e-02,  1.6396e-01, -6.5709e-02,  1.5986e-01,\n",
              "                       -1.7778e-03,  2.4396e-02, -1.3166e-02, -3.7218e-02,  1.7151e-02,\n",
              "                        1.2366e-01,  1.4765e-01, -3.3444e-02, -4.7050e-02,  9.0708e-03,\n",
              "                        2.5756e-02, -3.0022e-01, -2.3110e-03, -8.6661e-02,  1.0458e-03,\n",
              "                       -2.0388e-01, -6.5339e-02, -2.5439e-03, -5.2735e-02,  3.6884e-02,\n",
              "                       -3.5072e-02,  1.3448e-02, -6.1350e-02, -5.1994e-02,  1.8923e-02,\n",
              "                        4.1649e-02, -1.2104e-02, -8.9620e-02,  3.4459e-02, -5.2897e-02],\n",
              "                      [ 5.2359e-02,  5.7047e-02,  1.2461e-02,  2.9293e-01, -1.4447e-02,\n",
              "                       -1.1613e-02, -5.7947e-02,  3.1572e-02,  4.3267e-02,  7.2143e-02,\n",
              "                        4.9683e-02,  3.3667e-02,  7.1615e-02,  4.5732e-02,  7.2863e-02,\n",
              "                        6.0600e-02, -3.9375e-02,  4.0638e-02, -2.6198e-02,  1.4881e-02,\n",
              "                        3.8698e-02,  1.7626e-02,  9.3902e-02,  6.4448e-02,  7.7104e-03,\n",
              "                        6.9237e-02,  1.7645e-02,  7.6124e-03,  5.8076e-02,  8.2181e-03,\n",
              "                       -2.1551e-02,  6.1130e-02, -8.3240e-04,  3.3231e-02,  6.9502e-02,\n",
              "                        2.7226e-02,  3.3498e-02,  2.7142e-02,  6.8538e-03,  1.6312e-02,\n",
              "                        2.1691e-02,  1.9758e-02, -2.7620e-02, -9.3462e-02,  4.7931e-02,\n",
              "                       -6.0648e-03,  5.8491e-02,  8.3148e-03,  3.7516e-02,  4.9596e-02,\n",
              "                        6.8811e-02,  5.5274e-02,  8.9483e-03,  6.5748e-02,  8.9869e-02,\n",
              "                        8.2355e-02,  4.6395e-02,  2.0537e-02,  5.6605e-02,  4.0160e-02,\n",
              "                       -2.0782e-01,  8.0213e-03,  2.1325e-02,  1.8099e-02,  1.9334e-02,\n",
              "                        2.6324e-02,  4.3128e-02,  4.5984e-02,  1.5000e-01,  4.6890e-02,\n",
              "                       -1.0963e-02,  1.4446e-02, -3.9182e-02,  2.4810e-02,  2.6526e-02,\n",
              "                        5.9406e-02,  8.3714e-02,  7.9437e-02,  8.6315e-02,  6.1111e-02,\n",
              "                       -3.2706e-02,  3.5171e-02,  2.3281e-02,  3.4706e-02,  7.9344e-02,\n",
              "                       -1.4593e-01,  1.3831e-02, -4.6920e-02,  2.0715e-02,  2.1426e-02,\n",
              "                        1.0038e-02,  8.7019e-03, -3.9117e-02,  3.2423e-02, -2.2989e-02,\n",
              "                       -2.2580e-01,  1.6239e-02, -2.1522e-02,  4.8192e-03,  1.4925e-02,\n",
              "                        1.3689e-02,  5.0722e-02,  1.9152e-02,  3.8510e-02,  5.9229e-02,\n",
              "                       -8.4937e-03,  2.0478e-02,  1.9725e-02, -3.4409e-02,  3.6369e-02,\n",
              "                        7.5076e-02, -4.3333e-02,  6.8648e-02,  2.6216e-02,  5.1436e-02,\n",
              "                       -5.9052e-02,  7.4838e-04,  4.9325e-02,  7.1576e-02,  8.0565e-03,\n",
              "                        7.1655e-02,  1.6763e-02, -1.3620e-01,  4.2007e-02, -1.1545e-02,\n",
              "                        4.5606e-02,  2.0293e-02,  1.5560e-01, -3.4950e-02,  6.7453e-02,\n",
              "                       -5.5099e-02, -1.8446e-02,  6.6146e-02,  1.0702e-02, -4.1136e-02,\n",
              "                       -6.4769e-02, -2.3656e-02, -3.3376e-05,  1.1226e-01,  7.2691e-02,\n",
              "                        2.2961e-02,  5.2905e-02, -2.8709e-02,  4.9409e-03,  4.3710e-02,\n",
              "                        1.8911e-02,  1.1351e-02,  1.1149e-02,  6.0974e-02,  3.6874e-02,\n",
              "                        1.0221e-02,  5.0391e-02,  1.3024e-02, -4.5615e-02,  2.5938e-02,\n",
              "                        6.1454e-02,  2.0227e-01,  4.0101e-02,  1.5764e-02,  8.5840e-02,\n",
              "                        3.0604e-02,  2.7425e-02,  2.7642e-02,  3.7658e-02,  5.9203e-02,\n",
              "                       -5.2570e-03,  3.3253e-02,  9.3072e-03,  8.9229e-03,  1.5360e-02,\n",
              "                        7.3675e-03,  1.2550e-02,  5.3930e-02,  5.3814e-02,  1.2952e-01,\n",
              "                       -5.2292e-02,  1.5174e-02,  2.1689e-02,  2.1110e-02, -3.2596e-02,\n",
              "                        6.1149e-02,  5.8483e-02,  2.1218e-02, -1.8145e-02,  8.0242e-02,\n",
              "                        1.9147e-03, -1.1215e-01,  3.2793e-02,  2.0712e-02,  4.4821e-02,\n",
              "                       -1.3732e-02,  8.0170e-02, -1.0870e-02,  4.7129e-03,  3.7956e-01,\n",
              "                        2.9156e-02,  1.0599e-03,  1.0928e-01,  5.7913e-02, -9.7173e-03,\n",
              "                       -2.3747e-02,  2.6083e-02,  9.6794e-03, -2.3364e-02,  7.1247e-02,\n",
              "                        8.0457e-02, -5.4589e-03,  4.2195e-02, -1.3928e-02,  7.7726e-02,\n",
              "                        5.7242e-02, -3.7108e-03, -4.2371e-02,  6.9689e-02,  3.6361e-02,\n",
              "                       -3.7538e-02,  9.0062e-02, -2.6254e-02,  4.7298e-02, -2.7984e-02,\n",
              "                       -1.4853e-02,  9.5087e-02,  5.3103e-02, -2.8815e-03,  6.7592e-02,\n",
              "                        7.6540e-02,  4.6413e-02, -2.7906e-02, -3.6324e-02,  5.6669e-02,\n",
              "                        2.0985e-02,  2.5282e-02,  1.2684e-03,  5.5524e-02, -3.7291e-02,\n",
              "                       -1.3665e-01,  6.6836e-03,  8.4170e-02, -3.6025e-02, -5.1178e-02,\n",
              "                       -1.5402e-03,  1.3136e-02,  3.4411e-02,  1.2385e-02, -4.2883e-03,\n",
              "                        3.1552e-02, -2.9066e-02,  1.6949e-02, -1.9322e-02,  1.7827e-02,\n",
              "                        4.0346e-02, -4.1950e-02, -3.5701e-02,  2.7058e-02,  3.9232e-02,\n",
              "                        1.6155e-02, -7.7286e-03,  3.9232e-02,  1.6871e-02, -9.1689e-02,\n",
              "                        2.0378e-02, -1.1270e-02,  5.7333e-02,  1.2179e-02,  4.7465e-02,\n",
              "                       -5.6040e-02,  6.6524e-02,  1.1237e-03,  5.4008e-02,  6.1085e-02,\n",
              "                        6.3478e-02, -3.1664e-02,  7.9171e-02, -9.4739e-03,  6.8015e-02,\n",
              "                        7.1805e-02,  6.8330e-02,  5.0789e-02, -2.1396e-02, -8.2383e-03,\n",
              "                        1.1941e-02, -2.7856e-02,  3.3245e-02, -1.3984e-02,  6.4791e-02,\n",
              "                        5.8537e-02,  6.6109e-02, -2.9135e-02, -9.8259e-03, -1.6300e-02,\n",
              "                        1.9286e-02,  9.6178e-02,  2.5414e-02, -3.1361e-03, -4.7047e-03,\n",
              "                       -1.1349e-02,  4.2068e-02, -1.9468e-02,  4.4077e-02,  5.0144e-02,\n",
              "                       -8.1942e-03, -4.3473e-02,  5.9050e-03,  2.9052e-02, -5.0714e-02,\n",
              "                       -1.0847e-02,  3.4939e-03,  2.8960e-02,  7.4974e-02,  6.6974e-02,\n",
              "                        1.0008e-01,  1.8159e-01, -4.3415e-02,  6.0420e-02, -1.1613e-02,\n",
              "                        7.0599e-02, -1.3319e-02,  4.6459e-03,  3.0131e-02,  5.8771e-02,\n",
              "                        3.5440e-02,  1.4327e-02,  2.0855e-02, -3.2935e-02, -1.8791e-02,\n",
              "                        3.4719e-02, -2.7967e-02,  3.2846e-02, -3.5244e-03,  5.7241e-03,\n",
              "                        1.9855e-02,  4.3915e-02, -2.3604e-03,  2.3407e-02,  6.3633e-02,\n",
              "                        9.1211e-02, -4.7773e-03,  2.0882e-02,  8.1605e-02,  1.1102e-02,\n",
              "                       -1.7892e-02,  2.7568e-02,  5.7180e-03,  5.9165e-02, -6.4953e-02,\n",
              "                        7.0689e-03, -1.9048e-02,  4.9689e-02,  4.5441e-02,  3.1923e-02,\n",
              "                        5.1116e-03,  5.9782e-02, -3.5777e-03,  3.4819e-02,  3.3898e-02,\n",
              "                        1.7087e-02,  1.5544e-02,  5.6207e-02,  5.3454e-02,  4.9097e-02,\n",
              "                       -9.0136e-03,  5.1934e-02, -3.1678e-02,  2.9661e-02,  6.4498e-03,\n",
              "                        8.1890e-03, -4.8659e-02,  2.9791e-02,  6.8790e-03, -2.2575e-02,\n",
              "                        1.1501e-02, -1.9952e-02, -1.3395e-02, -2.2497e-02,  7.2892e-02,\n",
              "                        3.5696e-02, -8.4921e-04,  8.3851e-02, -2.5215e-01,  6.0959e-02,\n",
              "                       -3.6763e-02,  3.5635e-03,  6.3354e-02,  5.1712e-02,  4.9854e-02,\n",
              "                        1.7564e-02,  5.9811e-04, -1.4848e-02, -1.2410e-02,  8.2979e-02,\n",
              "                       -2.3404e-02,  2.8873e-02,  4.2742e-03,  5.2186e-02,  5.0703e-02,\n",
              "                        2.2798e-01,  1.2461e-03, -1.2429e-02,  7.1070e-02,  8.2254e-02,\n",
              "                        3.0104e-02, -5.1557e-02,  8.6556e-02,  2.3137e-02,  1.8707e-02,\n",
              "                       -3.3589e-02, -3.0031e-02,  9.7425e-02, -1.5664e-02,  3.2020e-02,\n",
              "                        1.0801e-02,  5.6902e-02, -8.5982e-02, -1.7006e-01,  3.5014e-02,\n",
              "                       -5.8436e-02,  2.0207e-02,  4.5626e-02,  4.8342e-02,  4.5991e-02,\n",
              "                       -6.1961e-04, -1.2598e-02,  1.6089e-02,  2.8810e-01,  2.2677e-02,\n",
              "                        6.4975e-02, -3.2548e-01, -2.4505e-02, -1.8402e-02, -2.1780e-02,\n",
              "                        1.0703e-02,  8.3289e-02, -1.9886e-02,  1.6703e-03, -3.6488e-02,\n",
              "                        6.6085e-02,  7.9707e-03, -2.1789e-02, -3.2988e-02, -1.1522e-02,\n",
              "                       -3.5049e-02,  3.4698e-02,  3.6627e-02,  5.9259e-02,  1.0761e-02,\n",
              "                       -1.8131e-02, -2.0284e-02, -1.9394e-02,  8.7266e-02, -2.2716e-02,\n",
              "                        4.6669e-03, -5.2309e-02,  7.2682e-02,  4.9435e-02,  6.9599e-03,\n",
              "                        2.1894e-02,  6.2143e-02, -1.4163e-01,  6.0183e-02,  1.1247e-02,\n",
              "                        6.0897e-02,  5.8963e-02,  4.8815e-02, -3.4302e-02, -8.5584e-04,\n",
              "                        1.8213e-02,  6.5502e-02, -1.7365e-01,  6.8936e-02, -2.1802e-01,\n",
              "                        1.7141e-02,  2.2441e-02,  3.8742e-02,  6.4062e-02,  4.9647e-03,\n",
              "                       -5.9338e-02, -1.4803e-01,  8.0088e-02,  4.3587e-02,  8.4691e-03,\n",
              "                       -3.3366e-02,  2.2937e-01, -6.6660e-03,  4.3245e-02, -1.7401e-02,\n",
              "                        2.2956e-01,  1.3113e-02, -2.9721e-02,  7.1977e-02, -1.7838e-03,\n",
              "                        4.5868e-02, -2.4837e-02,  7.6553e-02,  3.0041e-02,  5.6372e-03,\n",
              "                        1.9207e-02, -2.1391e-02,  2.6202e-02,  1.7905e-02,  5.3519e-02]])),\n",
              "             ('fc3.bias', tensor([ 0.0030, -0.0571]))])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'text_classifier_pytorch')"
      ],
      "metadata": {
        "id": "-Gn1GAK2SUBL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2iih--ASnME",
        "outputId": "db421869-1df5-4e68-8e23-dbbc0af3dac9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  text_classifier_pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "RdoRZB_hSp6U"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('text_classifier_pytorch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CvHW-0fsSwUE",
        "outputId": "a5b85ff7-0ddc-4cd2-e9a0-109a24087911"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4cafab91-b926-4e53-800d-cae6b9109ac3\", \"text_classifier_pytorch\", 1945173)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "0zHLjKkHS1CM"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vectorizer.pickle', 'wb') as file:\n",
        "  pickle.dump(vectorizer, file)"
      ],
      "metadata": {
        "id": "pYfTeqJDS6zN"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('vectorizer.pickle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3TJfMA0_TCTX",
        "outputId": "12077227-9dd2-4801-9c40-5ca87a3e8efe"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e465e42-6b2b-4ab4-8f1a-e09ba6ef16e2\", \"vectorizer.pickle\", 17070)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_GHeNBLlTMfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}